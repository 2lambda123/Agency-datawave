version: '2.2'
volumes:
  quickstart_data:
  hadoop_conf:

services:
  quickstart:
    profiles:
      - quickstart
    command: ["datawave-bootstrap.sh", "--accumulo"]
    image: datawave/quickstart-compose:3.21.0-SNAPSHOT
    environment:
      - DW_ACCUMULO_BIND_HOST=quickstart
    ports:
      # resource manager web ui
      - "8088:8088"
      # node manager web ui
      - "8042:8042"
      # namenode web ui
      - "9870:9870"
      # datanode web ui
      - "9864:9864"
      # jobhistory web ui
      - "8021:8021"
      # accumulo monitor
      - "9995:9995"
    volumes:
      - hadoop_conf:/opt/datawave/contrib/datawave-quickstart/hadoop/etc/hadoop
      - quickstart_data:/opt/datawave/contrib/datawave-quickstart/data
      - ./logs:/logs
    networks:
      - demo
    healthcheck:
      test: ["CMD-SHELL", "! accumuloStatus | grep DW-WARN > /dev/null"]

  consul:
    image: consul:1.9.8
    hostname: localhost
    environment:
      - 'CONSUL_LOCAL_CONFIG={"datacenter": "demo_dc", "disable_update_check": true, "enable_agent_tls_for_checks": true, "key_file": "/etc/pki/testServer.key", "cert_file": "/etc/pki/testServer.crt", "ca_file": "/etc/pki/testCA.pem", "verify_outgoing": true, "verify_server_hostname": false}'
      - CONSUL_BIND_INTERFACE=eth0
    # defined as host:container
    ports:
      - "8400"
      - "8500:8500"
      - "53"
    volumes:
      - ${PKI_DIR:-./pki}:/etc/pki:ro
    networks:
      - demo

  rabbitmq:
    image: rabbitmq:3.8.25-alpine
    volumes:
      - ${RABBITMQ_CONFIG_DIR:-./rabbitmq-config}:/etc/rabbitmq
      - ./logs:/logs
    environment:
      - TCP_PORTS=15672, 5672
      - RABBITMQ_ERLANG_COOKIE="mycookie"
    ports:
      - "15672:15672"
    networks:
      - demo
    depends_on:
      consul:
        condition: service_started

  zookeeper:
    image: bitnami/zookeeper:3.6.3
    ports:
      - "3181"
    networks:
      - demo
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
      - ZOO_PORT_NUMBER=3181

  kafka:
    image: bitnami/kafka:2
    ports:
      - "9093:9093"
    networks:
      - demo
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:3181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=CLIENT://:9092,EXTERNAL://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=CLIENT://kafka:9092,EXTERNAL://${DW_HOSTNAME}:9093
      - KAFKA_INTER_BROKER_LISTENER_NAME=CLIENT
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_CFG_DELETE_TOPICS_ENABLE=true
    depends_on:
      zookeeper:
        condition: service_started

  kafdrop:
    profiles:
      - management
      - full
    image: obsidiandynamics/kafdrop
    ports:
      - "8999:9000"
    networks:
      - demo
    environment:
      - "KAFKA_BROKERCONNECT=${DW_HOSTNAME}:9093"
    # This mapping is required to enable kafdrop to communicate with
    # the external, host-bound port for kafka
    extra_hosts:
      - "${DW_HOSTNAME}:${DW_HOST_IP}"
      - "${DW_HOST_FQDN}:${DW_HOST_IP}"
    depends_on:
      kafka:
        condition: service_started

  configuration:
    image: datawave/config-service:1.6-SNAPSHOT
    command:
      - --spring.output.ansi.enabled=ALWAYS
      - --spring.profiles.active=consul,native,open_actuator
      - --spring.cloud.consul.host=consul
      - --spring.cloud.config.server.native.searchLocations=file:///microservice-config
    environment:
      - 'KEYSTORE_LOCATION=file:///etc/pki/testServer.p12'
      - KEYSTORE_PASSWORD=ChangeIt
      - KEY_ALIAS=certificate
    ports:
      - "8888:8888"
    volumes:
      - ${CONFIG_DIR:-./config}:/microservice-config:ro
      - ${PKI_DIR:-./pki}:/etc/pki:ro
      - ./logs:/logs
    networks:
      - demo
    depends_on:
      rabbitmq:
        condition: service_started

  cache:
    image: datawave/hazelcast-service:1.9-SNAPSHOT
    scale: 1
    command:
      - --spring.profiles.active=consul,compose
      - --spring.output.ansi.enabled=ALWAYS
      - --spring.cloud.consul.host=consul
      - --spring.cloud.consul.discovery.instance-id=$${spring.application.name}:$${random.value}
    ports:
      - "5701-5703"
      - "8080"
      - "8443"
    volumes:
      - ${PKI_DIR:-./pki}:/etc/pki:ro
      - ./logs:/logs
    networks:
      - demo
    healthcheck:
      test: curl -f http://localhost:8080/cache/mgmt/health
      start_period: 36s
    depends_on:
      configuration:
        condition: service_started

  authorization:
    image: datawave/authorization-service:1.14-SNAPSHOT
    command:
      - --spring.output.ansi.enabled=ALWAYS
      - --spring.profiles.active=consul,mock,compose
      - --spring.cloud.consul.host=consul
      - --spring.cloud.consul.discovery.instance-id=$${spring.application.name}:$${random.value}
    ports:
      - "8080"
      - "8343:8443"
    volumes:
      - ${PKI_DIR:-./pki}:/etc/pki:ro
      - ./logs:/logs
    networks:
      - demo
    healthcheck:
      test: curl -f http://localhost:8080/authorization/mgmt/health
      start_period: 16s
    depends_on:
      cache:
        condition: service_healthy

  audit:
    image: datawave/audit-service:1.11-SNAPSHOT
    command:
      - --spring.output.ansi.enabled=ALWAYS
      - --spring.profiles.active=consul,compose
      - --spring.cloud.consul.host=consul
      - --spring.cloud.consul.discovery.instance-id=$${spring.application.name}:$${random.value}
    environment:
      - ZOOKEEPER_HOST=${DW_ZOOKEEPER_HOST}
    # This mapping is required to enable the audit service to communicate
    # with host-deployed services like hadoop, zookeeper, and accumulo.
    # These values are set locally in .env via bootstrap.sh
    extra_hosts:
      - "${DW_HOSTNAME}:${DW_HOST_IP}"
      - "${DW_HOST_FQDN}:${DW_HOST_IP}"
    ports:
      - "8080"
      - "8443"
    volumes:
      - ${PKI_DIR:-./pki}:/etc/pki:ro
      - ./logs:/logs
    networks:
      - demo
    healthcheck:
      test: curl -f http://localhost:8080/audit/mgmt/health
      start_period: 24s
    depends_on:
      authorization:
        condition: service_healthy

  metrics:
    entrypoint: ["java","-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5007","-jar","app.jar"]
    image: datawave/query-metric-service:1.5.4-SNAPSHOT
    command:
      - --spring.output.ansi.enabled=ALWAYS
      - --spring.profiles.active=consul,compose,remoteauth
      - --spring.cloud.consul.host=consul
      - --spring.cloud.consul.discovery.instance-id=$${spring.application.name}:$${random.value}
    environment:
      - ZOOKEEPER_HOST=${DW_ZOOKEEPER_HOST}
    # This mapping is required to enable the metrics service to communicate
    # with host-deployed services like hadoop, zookeeper, and accumulo.
    # These values are set locally in .env via bootstrap.sh
    extra_hosts:
      - "${DW_HOSTNAME}:${DW_HOST_IP}"
      - "${DW_HOST_FQDN}:${DW_HOST_IP}"
    ports:
      - "8180:8080"
      - "8543:8443"
      - "5007:5007"
    volumes:
      - ${PKI_DIR:-./pki}:/etc/pki:ro
      - ./logs:/logs
    networks:
      - demo
    healthcheck:
      test: curl -f http://localhost:8080/querymetric/mgmt/health
      start_period: 39s
    depends_on:
      authorization:
        condition: service_healthy

  dictionary:
    profiles:
      - dictionary
      - full
    image: datawave/dictionary-service:1.3-SNAPSHOT
    command:
      - --spring.output.ansi.enabled=ALWAYS
      - --spring.profiles.active=consul,compose,remoteauth
      - --spring.cloud.consul.host=consul
      - --spring.cloud.consul.discovery.instance-id=$${spring.application.name}:$${random.value}
    environment:
      - ZOOKEEPER_HOST=${DW_ZOOKEEPER_HOST}
    # This mapping is required to enable the metrics service to communicate
    # with host-deployed services like hadoop, zookeeper, and accumulo.
    # These values are set locally in .env via bootstrap.sh
    extra_hosts:
      - "${DW_HOSTNAME}:${DW_HOST_IP}"
      - "${DW_HOST_FQDN}:${DW_HOST_IP}"
    ports:
      - "8280:8080"
      - "8643:8443"
    volumes:
      - ${PKI_DIR:-./pki}:/etc/pki:ro
      - ./logs:/logs
    networks:
      - demo
    healthcheck:
      test: curl -f http://localhost:8080/dictionary/mgmt/health
    depends_on:
      authorization:
        condition: service_healthy

  query:
    entrypoint: ["java","-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005","-jar","app.jar"]
    image: datawave/query-service:1.0-SNAPSHOT
    command:
      - --spring.output.ansi.enabled=ALWAYS
      - --spring.profiles.active=consul,compose,remoteauth,storage,metricssource,query
      - --spring.cloud.consul.host=consul
      - --spring.cloud.consul.discovery.instance-id=$${spring.application.name}:$${random.value}
    environment:
      - AUDIT_SERVER_URL=http://audit:8080/audit
      - "BACKEND=${BACKEND:-kafka}"
    ports:
      - "8080:8080"
      - "8443:8443"
      - "5005:5005"
    volumes:
      - ${PKI_DIR:-./pki}:/etc/pki:ro
      - ./logs:/logs
    networks:
      - demo
    healthcheck:
      test: curl -f http://localhost:8080/query/mgmt/health
      start_period: 20s
    depends_on:
      audit:
        condition: service_healthy
      authorization:
        condition: service_healthy
      metrics:
        condition: service_healthy
      kafka:
        condition: service_started
      executor-pool1:
        condition: service_started

  executor-pool1:
    entrypoint: ["java","-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5006","-jar","app.jar"]
    image: datawave/query-executor-service:1.0-SNAPSHOT
    command:
      - --spring.application.name=executor-pool1
      - --spring.cloud.config.name=executor
      - --spring.output.ansi.enabled=ALWAYS
      - --spring.profiles.active=consul,compose,remoteauth,storage,metricssource,query,pool1
      - --spring.cloud.consul.host=consul
      - --spring.cloud.consul.discovery.instance-id=$${spring.application.name}:$${random.value}
    environment:
      - ZOOKEEPER_HOST=${DW_ZOOKEEPER_HOST}
      - HADOOP_HOST=${DW_HADOOP_HOST}
      - BACKEND=${BACKEND:-kafka}
      - HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-/etc/hadoop/conf}
    # This mapping is required to enable the metrics service to communicate
    # with host-deployed services like hadoop, zookeeper, and accumulo.
    # These values are set locally in .env via bootstrap.sh
    extra_hosts:
      - "${DW_HOSTNAME}:${DW_HOST_IP}"
      - "${DW_HOST_FQDN}:${DW_HOST_IP}"
    ports:
      - "8380:8080"
      - "8743:8443"
      - "5006:5006"
    volumes:
      - ${PKI_DIR:-./pki}:/etc/pki:ro
      - ./logs/pool1:/logs
      - ${HADOOP_CONF_DIR:-hadoop_conf}:${HADOOP_CONF_DIR:-/etc/hadoop/conf}:ro
    networks:
      - demo
    healthcheck:
      test: curl -f http://localhost:8080/executor-pool1/mgmt/health
      start_period: 24s
    depends_on:
      rabbitmq:
        condition: service_started
      authorization:
        condition: service_healthy
      metrics:
        condition: service_healthy
      kafka:
        condition: service_started

  executor-pool2:
    profiles:
      - pool2
      - full
    image: datawave/query-executor-service:1.0-SNAPSHOT
    command:
      - --spring.application.name=executor-pool2
      - --spring.cloud.config.name=executor
      - --spring.output.ansi.enabled=ALWAYS
      - --spring.profiles.active=consul,compose,remoteauth,storage,metricssource,query,pool2
      - --spring.cloud.consul.host=consul
      - --spring.cloud.consul.discovery.instance-id=$${spring.application.name}:$${random.value}
    environment:
      - ZOOKEEPER_HOST=${DW_ZOOKEEPER_HOST}
      - HADOOP_HOST=${DW_HADOOP_HOST}
      - BACKEND=${BACKEND:-kafka}
      - HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-/etc/hadoop/conf}
    # This mapping is required to enable the metrics service to communicate
    # with host-deployed services like hadoop, zookeeper, and accumulo.
    # These values are set locally in .env via bootstrap.sh
    extra_hosts:
      - "${DW_HOSTNAME}:${DW_HOST_IP}"
      - "${DW_HOST_FQDN}:${DW_HOST_IP}"
    ports:
      - "8480:8080"
      - "8843:8443"
    volumes:
      - ${PKI_DIR:-./pki}:/etc/pki:ro
      - ./logs/pool2:/logs
      - ${HADOOP_CONF_DIR:-hadoop_conf}:${HADOOP_CONF_DIR:-/etc/hadoop/conf}:ro
    networks:
      - demo
    healthcheck:
      test: curl -f http://localhost:8080/executor-pool2/mgmt/health
      start_period: 24s
    depends_on:
      rabbitmq:
        condition: service_started
      authorization:
        condition: service_healthy
      metrics:
        condition: service_healthy

  querystorage:
    profiles:
      - storage
      - full
    image: datawave/query-storage-service:1.0-SNAPSHOT
    command:
      - --spring.output.ansi.enabled=ALWAYS
      - --spring.profiles.active=consul,compose,remoteauth,storage,query
      - --spring.cloud.consul.host=consul
      - --spring.cloud.consul.discovery.instance-id=$${spring.application.name}:$${random.value}
    environment:
      - ZOOKEEPER_HOST=${DW_ZOOKEEPER_HOST}
    extra_hosts:
      - "${DW_HOSTNAME}:${DW_HOST_IP}"
      - "${DW_HOST_FQDN}:${DW_HOST_IP}"
    ports:
      - "8580:8080"
      - "8943:8443"
    volumes:
      - ${PKI_DIR:-./pki}:/etc/pki:ro
      - ./logs:/logs
    networks:
      - demo
    healthcheck:
      test: curl -f http://localhost:8080/query-storage/mgmt/health
    depends_on:
      authorization:
        condition: service_healthy

  # If you use the management center, you can connect to the hazelcast cache as follows:
  # In your browser connect to https://localhost:9043/
  # Enable 'dev' mode
  # Click 'Add Cluster Config'
  # Enter the following for the cache service:
  #  - Cluster Name: cache
  #  - Cluster Config: Enabled
  #  - Member Addresses: cache
  # Enter the following for the query metric service:
  #  - Cluster Name: metrics
  #  - Cluster Config: Enabled
  #  - Member Addresses: metrics
  # Use the console to view the cache contents
  #  - Select the 'cache' cluster
  #  - Select 'Console' under the 'CLUSTER' navigation entry
  #  - Run the following commands to list all entries in the 'datawaveUsers' map:
  #    - ns datawaveUsers
  #    - m.entries
  management-center:
    profiles:
      - management
      - full
    image: hazelcast/management-center:4.2021.06
    environment:
      - |-
        JAVA_OPTS=
        -Dhazelcast.mc.healthCheck.enable=true
        -Dhazelcast.mc.tls.enabled=true
        -Dhazelcast.mc.tls.keyStore=/etc/pki/testServer.p12
        -Dhazelcast.mc.tls.keyStorePassword=ChangeIt
        -Dhazelcast.mc.tls.trustStore=/etc/pki/testCA.p12
        -Dhazelcast.mc.tls.trustStorePassword=ChangeIt
    ports:
      - "8081"
      - "9043:8443"
    volumes:
      - ${PKI_DIR:-./pki}:/etc/pki:ro
    networks:
      - demo
    healthcheck:
      test: wget -q http://localhost:8081/health -O /dev/null || exit 1
    depends_on:
      cache:
        condition: service_healthy

networks:
  demo:
